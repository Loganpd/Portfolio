{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Project description\n",
    "This project is aimed at the analysis of the sentiments of users who purchased beauty products from Amazon during 2023. The dataset used for this task can be found on the huggingface website under this name: McAuley-Lab/Amazon-Reviews-2023 or at this link: https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\n",
    "\n",
    "# Objectives for sentiment analysis:\n",
    "- Understand Customer Opinions: Identify and analyze the emotions, opinions, and attitudes expressed in customer reviews.\n",
    "- Classify Sentiment: Automatically categorize text as positive or negative.\n",
    "- Monitor Brand Reputation: Track how people feel about a brand, product, or service over time to detect trends or issues early.\n",
    "- Improve Decision-Making: Provide actionable insights to marketing, product development, and customer service teams.\n",
    "- Automate Feedback Analysis: Reduce manual effort by using models to quickly process large volumes of textual data.\n",
    "\n",
    "# Plan of action\n",
    "- The preprocessing of texts will be done by two different methods\n",
    "    1. TF-IDF\n",
    "    2. Text embedding\n",
    "- The sentiment analysis task will be classified by different classification models.\n",
    "- A final best model will be selected based on computational expenses, accuracy, inference time, ..."
   ],
   "id": "f7d1718735ca38a7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T19:21:32.768671Z",
     "start_time": "2025-07-01T19:21:32.667546Z"
    }
   },
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading data",
   "id": "49cf34ba71076c90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# loading the dataset using the datasets library\n",
    "ds = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True);\n",
    "print(ds[\"full\"][\"features\"])\n",
    "\n",
    "# Extracting the input features and target values\n",
    "text = ds[\"full\"][\"text\"]\n",
    "stars = ds[\"full\"][\"rating\"]\n",
    "\n",
    "# Reviews are seen as either positive or negative. Ratings of 4 and 5 star are seen as positive.\n",
    "labels = np.array(stars)>3"
   ],
   "id": "d5e52a1d8bdab8c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TF-IDF + classification",
   "id": "cb56448242d05ff9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing for TF-IDF",
   "id": "3659523bcbbfc865"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:18:57.196480Z",
     "start_time": "2025-07-01T19:18:57.192351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_lemmatize(text):\n",
    "    \"\"\"\n",
    "    Cleans the text from URLs, punctuations, stopwords, numbers, and html tags and then lemmatizes it.\n",
    "    returns: cleaned text as a string\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    text = re.sub(r'<[^>]+>', '', text) # Remove html tags\n",
    "\n",
    "    # Tokenization and stopword removal\n",
    "    tokens = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# clean and lemmatize the review strings\n",
    "text = [clean_lemmatize(review) for review in text]\n",
    "\n",
    "# splitting the data into training and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(text, labels, test_size=0.2, random_state=42, stratify=labels)"
   ],
   "id": "61ae90bec439532f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification model selection",
   "id": "7093e8d835fd2bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T18:33:56.293634Z",
     "start_time": "2025-07-01T18:31:58.006859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# checking the performance of different models on the data\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Multinomial NB\": MultinomialNB()\n",
    "}\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# not viable to do 5-fold cross validation on the entire training set => 5% stratified sample is selected\n",
    "x_val, _, y_val, _ = train_test_split(x_train, y_train, test_size=0.95, random_state=42, stratify=y_train)\n",
    "print(\"5-Fold Cross-Validation Results:\\n\")\n",
    "cross_validation_results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(pipeline, x_val, y_val, cv=stratified_kfold, scoring='accuracy')\n",
    "    cross_validation_results[name] = scores.mean()\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy scores: {scores}\")\n",
    "    print(f\"  Mean Accuracy: {scores.mean():.4f}\")\n",
    "    print(f\"  Std Dev: {scores.std():.4f}\\n\")\n",
    "\n",
    "best_model_name = max(cross_validation_results, key=lambda x: cross_validation_results[x])\n",
    "print(f\"The best model based on mean accuracy is {best_model_name}\")"
   ],
   "id": "52d1d28fb6a78603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results:\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy scores: [0.86335293 0.8544191  0.85602281 0.86724875 0.85584462]\n",
      "  Mean Accuracy: 0.8594\n",
      "  Std Dev: 0.0050\n",
      "\n",
      "Linear SVM:\n",
      "  Accuracy scores: [0.86477819 0.85548824 0.85334996 0.86154669 0.84907341]\n",
      "  Mean Accuracy: 0.8568\n",
      "  Std Dev: 0.0056\n",
      "\n",
      "Random Forest:\n",
      "  Accuracy scores: [0.85230714 0.8424804  0.84978617 0.85352815 0.84889522]\n",
      "  Mean Accuracy: 0.8494\n",
      "  Std Dev: 0.0038\n",
      "\n",
      "Multinomial NB:\n",
      "  Accuracy scores: [0.78157848 0.77833215 0.77423378 0.77583749 0.77583749]\n",
      "  Mean Accuracy: 0.7772\n",
      "  Std Dev: 0.0026\n",
      "\n",
      "The best model based on mean accuracy is Logistic Regression\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## inference timing",
   "id": "d81ec35c69061e04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T18:34:23.041843Z",
     "start_time": "2025-07-01T18:34:11.349458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(text)\n",
    "y = labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=labels)\n",
    "model = models[best_model_name]\n",
    "model.fit(x_train, y_train)"
   ],
   "id": "1738303a9440e4fe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T18:38:47.847684Z",
     "start_time": "2025-07-01T18:38:42.659221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "text = ds[\"full\"][\"text\"][137854]\n",
    "text = clean_lemmatize(text)\n",
    "x = vectorizer.transform([text])\n",
    "pred = model.predict(x)"
   ],
   "id": "140cb6b949df57c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645 ms ± 5.05 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text embedding + classification",
   "id": "f90e738c6d9b52a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:03:05.853071Z",
     "start_time": "2025-07-01T19:02:52.948451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r'<[^>]+>', '', text) # Remove html tags\n",
    "    return text\n",
    "\n",
    "def embed_text(text, model):\n",
    "    embedding = model.encode(text, convert_to_tensor=False, batch_size=256, show_progress_bar=True)\n",
    "    return embedding\n",
    "\n",
    "text = ds[\"full\"][\"text\"]\n",
    "text = [clean_text(review) for review in text]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')     # Alternatives: 'paraphrase-MiniLM-L3-v2', 'all-distilroberta-v1'\n",
    "# # embeddings = embed_text(text, model)\n",
    "# # pd.DataFrame(embeddings).to_parquet(\"embeddings.parquet\") # saving the embeddings to file\n",
    "embeddings = pd.read_parquet(\"embeddings.parquet\")# loading the embeddings from file\n",
    "x_train, x_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42, stratify=labels)"
   ],
   "id": "fa142ee33dee822e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T18:51:08.316798Z",
     "start_time": "2025-07-01T18:46:58.314984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# checking the performance of different models on the data\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    \"Linear SVM\": LinearSVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# not viable to do 5-fold cross validation on the entire training set => 1% stratified sample is selected\n",
    "x_val, _, y_val, _ = train_test_split(x_train, y_train, test_size=0.95, random_state=42, stratify=y_train)\n",
    "print(\"5-Fold Cross-Validation Results:\\n\")\n",
    "cross_validation_results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([('clf', model)])\n",
    "\n",
    "    scores = cross_val_score(pipeline, x_val, y_val, cv=stratified_kfold, scoring='accuracy')\n",
    "    cross_validation_results[name] = scores.mean()\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy scores: {scores}\")\n",
    "    print(f\"  Mean Accuracy: {scores.mean():.4f}\")\n",
    "    print(f\"  Std Dev: {scores.std():.4f}\\n\")\n",
    "\n",
    "best_model_name = max(cross_validation_results, key=lambda x: cross_validation_results[x])\n",
    "print(f\"The best model based on mean accuracy is {best_model_name}\")"
   ],
   "id": "1412ca597d4829ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Results:\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy scores: [0.86032425 0.85940841 0.8629722  0.86582324 0.86065574]\n",
      "  Mean Accuracy: 0.8618\n",
      "  Std Dev: 0.0023\n",
      "\n",
      "Linear SVM:\n",
      "  Accuracy scores: [0.86032425 0.8647541  0.86404134 0.86920884 0.8629722 ]\n",
      "  Mean Accuracy: 0.8643\n",
      "  Std Dev: 0.0029\n",
      "\n",
      "Random Forest:\n",
      "  Accuracy scores: [0.811509   0.81628653 0.81200998 0.81468282 0.81307912]\n",
      "  Mean Accuracy: 0.8135\n",
      "  Std Dev: 0.0018\n",
      "\n",
      "The best model based on mean accuracy is Linear SVM\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## inference timing",
   "id": "aa0d3dac29aa9cdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:03:59.381603Z",
     "start_time": "2025-07-01T19:03:44.585934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedder_model = SentenceTransformer('all-MiniLM-L6-v2')     # Alternatives: 'paraphrase-MiniLM-L3-v2', 'all-distilroberta-v1'\n",
    "model = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "model.fit(x_train, y_train);"
   ],
   "id": "7a578618fae5d601",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:04:58.567094Z",
     "start_time": "2025-07-01T19:04:52.838342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "text = ds[\"full\"][\"text\"][137854]\n",
    "text = clean_text(text)\n",
    "embedding = embed_text(text, embedder_model)\n",
    "pred = model.predict(embedding.reshape(1, -1))"
   ],
   "id": "b7e3b90f6f3a7689",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e219fd7115b84d8d9d8d64735a9f6633"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebf61e720c0e496b9a4c27ef08cc54c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f0e665d693148e7ba15bce9375dd91d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3493fdc0c43d4059bb92a686d214379d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36d7d6c734b24fe69ec2f629797ee7c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78ca709bb55d4c4eaedcf7d3f5ff8ece"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97779cdd9a704e4a9a3eaeb52c46cd44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72dd5ec4788f41fe93ab7bd8b3c0fc0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715 ms ± 12.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final model evaluation\n",
   "id": "dc8b79a27f7534f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:23:17.180282Z",
     "start_time": "2025-07-01T19:21:37.771562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = ds[\"full\"][\"text\"]\n",
    "text = [clean_lemmatize(review) for review in text]\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_texts = vectorizer.fit_transform(text)\n",
    "x_train, x_test, y_train, y_test = train_test_split(vectorized_texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.4f}%\")"
   ],
   "id": "3b52ae4601583669",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.9791%\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary and conclusions\n",
    "- Model comparisons are done through 5-fold cross validation scores.\n",
    "- The best model was found to be Text Embedding (with the all-MiniLM-L6-v2 model) + Linear SVM classifier with a cross validation score of 86.43%.\n",
    "- The next best model was found to be TF-IDF + Logistic Regression with a cross validation score of 85.94%.\n",
    "- The TF-IDF method seems to offer lower computational costs due to not needing GPUs, while offering competitive performance.\n",
    "- The most suitable model was selected as TF-IDF + Logistic Regression and offered a test accuracy of 87.98%.\n",
    "- The same methods can be used for different families of products to observe and track user opinions on products and brands over time."
   ],
   "id": "9ed8cac2b8fa2469"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

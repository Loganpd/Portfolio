{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-03T23:26:36.822759Z",
     "start_time": "2025-07-03T23:26:35.346745Z"
    }
   },
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T22:40:53.812381Z",
     "start_time": "2025-07-03T22:40:51.544155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')\n",
    "\n",
    "# Load the trained PyTorch model\n",
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
    "resnet50.eval().to(device)\n",
    "\n",
    "url = \"https://github.com/marcin-laskowski/ml-fastapi-docker/blob/main/sample_data/input.jpg?raw=true\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url=url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Load into PIL for processing\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    width, height = image.size\n",
    "except Exception as e:\n",
    "    raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "# Apply transformations and make a prediction\n",
    "with torch.no_grad():\n",
    "    output = torch.nn.functional.softmax(resnet50(utils.prepare_input_from_uri(url).to(device)), dim=1)\n",
    "    results = utils.pick_n_best(predictions=output, n=3)\n",
    "print(results)\n"
   ],
   "id": "facc87cc2c563b44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/logan/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in /home/logan/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: [('hotdog, hot dog, red hot', '73.2%'), ('strawberry', '0.1%'), ('peacock', '0.1%')]\n",
      "[[('hotdog, hot dog, red hot', '73.2%'), ('strawberry', '0.1%'), ('peacock', '0.1%')]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = requests.get(url=url)\n",
    "response.raise_for_status()\n",
    "image = Image.open(BytesIO(response.content))\n",
    "width, height = image.size"
   ],
   "id": "8f089ebd95d0dc1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
